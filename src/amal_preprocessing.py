# -*- coding: utf-8 -*-
"""Copy of ubdate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fv9Hz1I782RY1oYsRIEQM7lxLh5JKG5r
"""

import pandas as pd
import collections, numpy,os
from collections import Counter
import numpy as np
from sklearn.preprocessing import LabelEncoder
import re

df = pd.read_excel('/content/Amal Twitts.xlsx')

"""##Cleaning"""

!git clone https://github.com/UBC-NLP/aoc_id.git

from aoc_id import text_normalization

df['norm_text'] = df.text.apply(lambda text: text_normalization.clean_unicode(str(text)))

# to remove retweeted tweets as they cannot be lnger than 140 chars and usulally contain repeated info 
match = 'RT'
print('Number of Tweets before removing rows contain unwnated word: ',df.shape)
df = df[df['text'].str.contains(match)==False]
print('Number of Tweets after removing rows contain unwnated word: ',df.shape)

# to remove duplicates from clean text column
print('Number of Tweets before removing duplicates: ',df.shape)
df = df.drop_duplicates(['norm_text'])
print('Number of Tweets after removing duplicates: ',df.shape)

# function to find URL
def ck_url(x):
  re_equ = r"(?i)\b((?:https?://|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>]+|\(([^\s()<>]+|(\([^\s()<>]+\)))*\))+(?:\(([^\s()<>]+|(\([^\s()<>]+\)))*\)|[^\s`!()\[\]{};:'\".,<>?«»“”‘’]))"
  ck_url = re.findall(re_equ, x)
  if ck_url:
      return True
  else:
      return False

# to remove tweets that contain URL
print('Number of Tweets before removing URLs: ',df.shape)
df = df[df['text'].apply(ck_url) == False]
print('Number of Tweets after removing URLs: ',df.shape)

df.info()

columns_to_drop = ['created_at','tweet_id','author_id','author_description','replies','author_location']
df = df.drop(columns=columns_to_drop)

df.dropna()

df.to_csv('cleaned_data.csv')

"""**To predict sentiment analsis based on MAZAJAK model**"""

import requests
import json

'''
This function offers the ability to predict the sentiment of a single sentence 
through the API, the sentiment is one of three classes (positive negative, neutral)
Input: 
        sentence(str): the input sentence of which the sentiment is to be predicted
Output:
        prediction(str): the sentiment of the given sentence 
'''


def predict(sentence):
    url = "http://mazajak.inf.ed.ac.uk:8000/api/predict"
    to_sent = {'data': sentence}
    data = json.dumps(to_sent,ensure_ascii=False).encode('utf8')
    headers = {'content-type': 'application/json'}
    # sending get request and saving the response as response object
    response = requests.post(url=url, data=data, headers=headers)

    prediction = json.loads(response.content)['data']

    return prediction


'''
This function offers the ability to predict the sentiment of a list of sentences
through the API, the sentiment is one of three classes (positive negative, neutral)
Input: 
        sent_lst(list of str): the input list of which the sentiment of its sentences is to be predicted
Output:
        prediction(list of str): the sentiments of the given sentences
'''


def predict_list(sent_lst):
    url = "http://mazajak.inf.ed.ac.uk:8000/api/predict_list"
    to_sent = {'data': sent_lst}
    data = json.dumps(to_sent)
    headers = {'content-type': 'application/json'}
    # sending get request and saving the response as response object
    response = requests.post(url=url, data=data, headers=headers)

    prediction = json.loads(response.content)['data']

    return prediction

tweets = df['norm_text'].to_list()
labels = []
for tweet in tweets:
    labels.append(predict(tweet))

df["auto_lable"]= labels

df["auto_lable"].value_counts()

df

df.to_csv('Lable_data.csv')

df.info()

df.loc[df['auto_lable']=='positive',:]

df.loc[df['auto_lable']=='negative',:]

df.loc[df['auto_lable']=='neutral',:]



"""**To predict sentiment analsis based on Camels model**"""

!pip install camel_tools

from camel_tools.sentiment import SentimentAnalyzer
sa = SentimentAnalyzer("CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment")

df['camel_labe'] = df.norm_text.apply(lambda text: sa.predict(str(text)))

df['camel_labe']

df

df.to_csv('Camels_data.csv')